{"version":3,"file":"rx-storage.d.js","names":[],"sources":["../../../src/types/rx-storage.d.ts"],"sourcesContent":["import type { ChangeEvent } from 'event-reduce-js';\nimport type { RxChangeEvent } from './rx-change-event.d.ts';\nimport type { RxDocumentMeta } from './rx-document.d.ts';\nimport type { RxStorageWriteError } from './rx-error.d.ts';\nimport type { RxJsonSchema } from './rx-schema.d.ts';\nimport type { Override } from './util.d.ts';\n\n/**\n * The document data how it comes out of the storage instance.\n * Contains all meta data like revision, attachments and deleted-flag.\n */\nexport type RxDocumentData<T> = T & {\n\n    /**\n     * As other NoSQL databases,\n     * RxDB also assumes that no data is finally deleted.\n     * Instead the documents are stored with _deleted: true\n     * which means they will not be returned at queries.\n     */\n    _deleted: boolean;\n\n    /**\n     * The attachments meta data is stored besides to document.\n     */\n    _attachments: {\n        [attachmentId: string]: RxAttachmentData;\n    };\n\n    /**\n     * Contains a revision which is concatenated with a [height: number]-[identifier: string]\n     * like: '1-3hl4kj3l4kgj34g34glk'.\n     * The revision is used to detect write conflicts and have a document history.\n     * Revisions behave similar to couchdb revisions:\n     * @link https://docs.couchdb.org/en/stable/replication/conflicts.html#revision-tree\n\n    * When writing a document, you must send the correct revision in the previous-field\n     * to make sure that you do not cause a write conflict.\n     * The revision of the 'new' document-field must be created, for example via util.createRevision().\n     * Any revision that matches the [height]-[hash] format can be used.\n     */\n    _rev: string;\n    _meta: RxDocumentMeta;\n};\n\nexport type RxDocumentDataById<RxDocType> = {\n    [documentId: string]: RxDocumentData<RxDocType>;\n};\n\n/**\n * The document data how it is send to the\n * storage instance to save it.\n */\n// We & T here instead of in RxDocumentData to preserver indexability by keyof T which the Override breaks\nexport type RxDocumentWriteData<T> = T & Override<RxDocumentData<{}>, {\n    _attachments: {\n        /**\n         * To create a new attachment, set the write data\n         * To delete an attachment, leave it out on the _attachments property.\n         * To change an attachment, set the new write data.\n         * To not touch an attachment, just send the stub again\n         * which came out of the storage instance.\n         */\n        [attachmentId: string]: RxAttachmentData | RxAttachmentWriteData;\n    };\n}>;\n\nexport type WithDeleted<DocType> = DocType & {\n    _deleted: boolean;\n};\nexport type WithDeletedAndAttachments<DocType> = DocType & {\n    _deleted: boolean;\n\n    /**\n     * Here the _attachments might exist\n     * or might not, depending one the use case.\n     */\n    _attachments?: {\n        [attachmentId: string]: RxAttachmentData | RxAttachmentWriteData;\n    };\n};\n\n/**\n * Send to the bulkWrite() method of a storage instance.\n */\nexport type BulkWriteRow<RxDocType> = {\n    /**\n     * The current document state in the storage engine,\n     * assumed by the application.\n     * Undefined if the document is a new insert.\n     * Notice that we send the full document data as 'previous', not just the revision.\n     * The reason is that to get the previous revision you anyway have to get the full\n     * previous document and so it is easier to just send it all to the storage instance.\n     * This will later allow us to use something different then the _rev key for conflict detection\n     * when we implement other storage instances.\n     */\n    previous?: RxDocumentData<RxDocType>;\n    /**\n     * The new document data to be stored in the storage instance.\n     */\n    document: RxDocumentWriteData<RxDocType>;\n};\nexport type BulkWriteRowById<RxDocType> = {\n    [documentId: string]: BulkWriteRow<RxDocType>;\n};\n\n/**\n * After the RxStorage has processed all rows,\n * we have this to work with afterwards.\n */\nexport type BulkWriteRowProcessed<RxDocType> = BulkWriteRow<RxDocType> & {\n    document: RxDocumentData<RxDocType>;\n};\n\n\nexport type RxAttachmentData = {\n    /**\n     * Size of the attachments data\n     */\n    length: number;\n    /**\n     * Content type like 'plain/text'\n     */\n    type: string;\n    /**\n     * The hash of the attachments content.\n     * It is calculated by RxDB, and send to the storage.\n     * The only guarantee is that the digest will change when the attachments data changes.\n     * @link https://github.com/pouchdb/pouchdb/issues/3156#issuecomment-66831010\n     * @link https://github.com/pubkey/rxdb/pull/4107\n     */\n    digest: string;\n};\n\n/**\n * Data which is needed for new attachments\n * that are send from RxDB to the RxStorage implementation.\n */\nexport type RxAttachmentWriteData = RxAttachmentData & {\n    /**\n     * The data of the attachment. As string in base64 format.\n     * In the past we used Blob internally but it created many\n     * problems because of then we need the full data (for encryption/compression)\n     * so we anyway have to get the string value out of the Blob.\n     *\n     * Also using Blob has no performance benefit because in some RxStorage implementations,\n     * it just keeps the transaction open for longer because the Blob\n     * has be be read.\n     */\n    data: string;\n};\n\n\n/**\n * The returned data from RxStorageInstance.bulkWrite()\n * For better performance, we do NOT use an indexed object,\n * but only plain arrays. Because most of the time\n * RxDB anyway only need the array data and we can save performance\n * by not indexing the results.\n */\nexport type RxStorageBulkWriteResponse<RxDocType> = {\n    /**\n     * contains all succeeded writes.\n     */\n    success: RxDocumentData<RxDocType>[];\n    /**\n     * contains all errored writes.\n     */\n    error: RxStorageWriteError<RxDocType>[];\n};\n\n/**\n * We return a complex object instead of a single array\n * so we are able to add additional fields in the future.\n */\nexport type RxStorageQueryResult<RxDocType> = {\n    // the found documents, sort order is important.\n    documents: RxDocumentData<RxDocType>[];\n};\n\nexport type RxStorageCountResult = {\n    count: number;\n    /**\n     * Returns the mode which was used by the storage\n     * to count the documents.\n     * If this returns 'slow', RxDB will throw by default\n     * if 'allowSlowCount' is not set.\n     */\n    mode: 'fast' | 'slow';\n};\n\nexport type RxStorageInstanceCreationParams<RxDocType, InstanceCreationOptions> = {\n\n    /**\n     * A string to uniquely identify the instance of the JavaScript object\n     * of the RxDatabase where this RxStorageInstance belongs to.\n     * In most cases you would use RxDatabase.token here.\n     *\n     * This is used so that we can add caching or reuse stuff that belongs to the same RxDatabase.\n     * For example the BroadcastChannel that is used for event propagation between multiple browser tabs\n     * is cached by this token.\n     *\n     * In theory we could just use the databaseName for that. But to make it easier in unit tests\n     * to simulate cross-tab usage, we cannot assume that the databaseName is unique in a single\n     * JavaScript process. Therefore we use the instance token instead.\n     */\n    databaseInstanceToken: string;\n\n\n    databaseName: string;\n    collectionName: string;\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>;\n    options: InstanceCreationOptions;\n    /**\n     * If multiInstance is true, there can be more\n     * then one instance of the database, for example\n     * when multiple browser tabs exist or more then one Node.js\n     * process relies on the same storage.\n     */\n    multiInstance: boolean;\n    password?: string | any;\n\n    /**\n     * Some storages can do additional checks\n     * that are performance expensive\n     * and should only be done in dev-mode.\n     */\n    devMode: boolean;\n};\n\nexport type ChangeStreamOptions = {\n\n    /**\n     * Sequence number of the first event to start with.\n     * If you want to get all ongoing events,\n     * first get the latest sequence number and input it here.\n     *\n     * Optional on changeStream,\n     * will start from the newest sequence.\n     */\n    startSequence?: number;\n    /**\n     * limits the amount of results\n     */\n    limit?: number;\n};\n\n/**\n * In the past we handles each RxChangeEvent by its own.\n * But it has been shown that this take way more performance then needed,\n * especially when the events get transferred over a data layer\n * like with WebWorkers or the BroadcastChannel.\n * So we now process events as bulks internally.\n */\nexport type EventBulk<EventType, CheckpointType> = {\n    /**\n     * Unique id of the bulk,\n     * used to detect duplicate bulks\n     * that have already been processed.\n     */\n    id: string;\n    events: EventType[];\n\n    /**\n     * Required for replication.\n     * Passing this checkpoint into getChangedDocumentsSince()\n     * must return all items that have been modified AFTER this write event.\n     */\n    checkpoint: CheckpointType;\n\n    /**\n     * The context that was given at the call to bulkWrite()\n     * that caused this EventBulk.\n     */\n    context: string;\n\n    /**\n     * Unix timestamp in milliseconds of when the operation was triggered\n     * and when it was finished.\n     * This is optional because we do not have this time\n     * for events that come from the internal storage instance changestream.\n     * TODO do we even need this values?\n     */\n    startTime: number;\n    endTime: number;\n};\n\nexport type ChangeStreamEvent<DocType> = ChangeEvent<RxDocumentData<DocType>> & {\n    /**\n     * An integer that is increasing\n     * and unique per event.\n     * Can be used to sort events or get information\n     * about how many events there are.\n     */\n    sequence: number;\n    /**\n     * The value of the primary key\n     * of the changed document\n     */\n    id: string;\n};\n\nexport type RxStorageChangeEvent<RxDocType> = Omit<RxChangeEvent<RxDocType>, 'isLocal' | 'collectionName'>;\n\n/**\n * An example for how a RxStorage checkpoint can look like.\n * NOTICE: Not all implementations use this type.\n */\nexport type RxStorageDefaultCheckpoint = {\n    id: string;\n    lwt: number;\n};\n\n\n\n\nexport type CategorizeBulkWriteRowsOutput<RxDocType> = {\n\n    // TODO only needs the document, not the row.\n    bulkInsertDocs: BulkWriteRowProcessed<RxDocType>[];\n    bulkUpdateDocs: BulkWriteRowProcessed<RxDocType>[];\n\n    errors: RxStorageWriteError<RxDocType>[];\n    eventBulk: EventBulk<RxStorageChangeEvent<RxDocumentData<RxDocType>>, any>;\n    attachmentsAdd: {\n        documentId: string;\n        attachmentId: string;\n        attachmentData: RxAttachmentWriteData;\n        digest: string;\n    }[];\n    attachmentsRemove: {\n        documentId: string;\n        attachmentId: string;\n        digest: string;\n    }[];\n    attachmentsUpdate: {\n        documentId: string;\n        attachmentId: string;\n        attachmentData: RxAttachmentWriteData;\n        digest: string;\n    }[];\n    /**\n     * Contains the non-error document row that\n     * has the newest _meta.lwt time.\n     * Empty if no successful write exists.\n     */\n    newestRow?: BulkWriteRowProcessed<RxDocType>;\n};\n"],"mappings":"","ignoreList":[]}